import streamlit as st
import streamlit.components.v1 as components
import openai
from openai import OpenAI  # OpenAI í´ë˜ìŠ¤ ê°€ì ¸ì˜¤ê¸°
import pandas as pd
import json
import plotly.express as px
from prompts import *

# ğŸ“Œ ë‹µë³€ ì´ˆê¸°í™”
is_answer = [True, True, True, True]

# ğŸ“Œ Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± í•¨ìˆ˜
def mermaid(code):
    """ Mermaid ë‹¤ì´ì–´ê·¸ë¨ì„ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜ """
    components.html(
        f"""
        <pre class="mermaid">
            {code}
        </pre>
        <script type="module">
            import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";
            mermaid.initialize({{ startOnLoad: true, theme: "dark" }});
        </script>
        """,
        height=500,
    )

# ğŸ“Œ OpenAI ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ (GPT)
# @st.cache_data # ìºì‹œ ë°ì´í„° ì‚¬ìš©
def get_gpt_response(model, prompt, stream=False):
    # ì„¸ì…˜ì—ì„œ API í‚¤ ìœ ì§€
    api_key = st.session_state.get("openai_api_key", "")
    
    if not api_key:
        st.error("ğŸš¨ OpenAI API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        return None
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
    client = OpenAI(api_key=api_key)

    # OpenAI GPT ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
    response = client.chat.completions.create(
        model=model,
        messages=prompt,
        stream=stream
    )
    return response


# ğŸ“Œ Streamlit UI ì„¤ì •
st.set_page_config(page_title="Dream Trip - Uway AI ì§„ë¡œ ê²€ì‚¬", layout="wide", page_icon="â­ï¸")

st.header("Dream Trip âœˆï¸âœ¨", divider="rainbow")
st.info("ê¿ˆì„ ìœ„í•œ ë§ì¶¤ ì§„ë¡œ ì—¬í–‰!\n\nì§„ë¡œÂ·ëª©í‘œ ì„¤ì • â†’ ìŠ¤í…ë³„ ê°€ì´ë“œ â†’ ì»¤ë¦¬ì–´ ëª©í‘œ ë‹¬ì„±", icon="âœˆï¸")


# ğŸ“Œ Sidebar (ì‚¬ìš©ì ì…ë ¥)
with st.sidebar:
    st.header("Uway - Dream Trip âœˆï¸", divider="rainbow")

    # api session ì…ë ¥ ì •ë³´
    openai.api_key = st.text_input(label='OpenAI API KEY', placeholder='OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.', value='',type='password')
    if openai.api_key:
        st.session_state["openai_api_key"] = openai.api_key
    st.markdown("---")

    # ì‚¬ìš©ì ì…ë ¥ í¼
    with st.form("parameters-form"):
        st.subheader("ì‚¬ìš©ì ì •ë³´")
        name = st.text_input("ì´ë¦„")
        job = st.text_input("í¬ë§ ì§ì—…")
        age = st.slider("ë‚˜ì´", 10, 20, 17, 1)
        gender = st.radio("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"])
        school = st.selectbox("í•™êµ", ["ì¤‘í•™êµ", "ê³ ë“±í•™êµ", "ëŒ€í•™êµ"], index=1)
        mbti = st.selectbox("MBTI", [
            "ISTJ", "ISFJ", "INFJ", "INTJ", "ISTP", "ISFP", "INFP", "INTP",
            "ESTP", "ESFP", "ENFP", "ENTP", "ESTJ", "ESFJ", "ENFJ", "ENTJ"])
        language = st.selectbox("ì–¸ì–´ì„¤ì •", ["ëŒ€í•œë¯¼êµ­", "English", "æ—¥æœ¬", "ä¸­åœ‹"])

        # ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì ìš©
        st.markdown("""
            <style>
                div[data-testid="stForm"] button {
                    width: 100% !important;
                    height: 50px !important;
                    font-size: 16px !important;
                    font-weight: bold !important;
                    background-color: #ff4b4b !important;
                    color: white !important;
                    border-radius: 10px !important;
                    border: none !important;
                }
                div[data-testid="stForm"] button:hover {
                    background-color: #ff7878 !important;
                }
            </style>
        """, unsafe_allow_html=True)

        submit = st.form_submit_button("ì§„ë¡œ ì—¬í–‰ ì‹œì‘í•˜ê¸°")


# ğŸ“Œ OpenAI í”„ë¡¬í”„íŠ¸ ì´ˆê¸° ì„¤ì •
gpt_prompt = [{"role": "system", "content": system_prompt}]


# ğŸ“Œ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if submit and name and job:
    new_gpt_prompt = gpt_prompt.copy()
    new_user_prompts = user_prompts.copy()

    # ğŸš€ 1ë‹¨ê³„: ê¿ˆì˜ ì—¬í–‰ì§€
    if is_answer[0]:
        st.subheader(f"{name}ë‹˜ì˜ ê¿ˆì„ í–¥í•œ ë§ì¶¤ ì—¬í–‰ì§€ ğŸŒˆ", divider=True)
        answer1 = st.empty()

        with st.spinner("ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ì—¬í–‰ì§€ í‹°ì¼“ì„ ë°œí–‰ ì¤‘ì´ì—ìš”..."):
            new_gpt_prompt.append({
                "role": "user",
                "content": new_user_prompts[0] % (name, age, gender, job, school, language, mbti)
            })

            # âœ… `stream=True` ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            gpt_response1 = get_gpt_response("gpt-4o-mini", new_gpt_prompt, stream=True)

            collected_messages = []
            full_response = ""

            for chunk in gpt_response1:
                if isinstance(chunk, tuple):  # ğŸ”¥ íŠœí”Œì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
                    chunk = chunk[0]

                if hasattr(chunk, "choices") and hasattr(chunk.choices[0], "delta") and hasattr(chunk.choices[0].delta, "content"):
                    content = chunk.choices[0].delta.content
                    if content is not None:  # ğŸ”¥ None ê°’ ë°©ì§€
                        collected_messages.append(content)
                    full_response = "".join(collected_messages)

                    # âœ… ì‹¤ì‹œê°„ìœ¼ë¡œ UI ì—…ë°ì´íŠ¸
                    answer1.markdown(f"ğŸ¤– {full_response}")

            new_gpt_prompt.append({"role": "assistant", "content": full_response})
            

    # ğŸš€ 2ë‹¨ê³„: ê¿ˆìœ¼ë¡œ ê°€ëŠ” ë¡œë“œë§µ
    if is_answer[1]:
        st.subheader(f"{name}ë‹˜ì˜ ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ë¡œë“œë§µ ğŸ—ºï¸ğŸŒŸ", divider=True)
        with st.spinner("ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ë¡œë“œë§µì„ ê·¸ë¦¬ëŠ” ì¤‘ì´ì—ìš”..."):
            new_gpt_prompt.append({
                "role": "user",
                "content": new_user_prompts[1] % (name, age, gender, job, school, language, mbti),
            })

            gpt_response2 = get_gpt_response("gpt-4o-mini", new_gpt_prompt, stream=False)
            gpt_response2 = gpt_response2.choices[0].message.content

            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ íŒŒì‹± ë° ë Œë”ë§
            start_keyword, end_keyword = "```mermaid", "```"
            if start_keyword in gpt_response2 and end_keyword in gpt_response2:
                mermaid_content = gpt_response2.split(start_keyword)[-1].split(end_keyword)[0].strip()
            else:
                mermaid_content = gpt_response2

            mermaid(mermaid_content)


    # ğŸš€ 3ë‹¨ê³„: ì§ì—… ë¶„ì„ ê²°ê³¼
    if is_answer[2]:
        st.subheader(f"AIê°€ ë¶„ì„í•œ {job} ğŸ”ğŸ‘¨â€ğŸ’¼", divider=True)
    with st.spinner("ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ëŠ¥ë ¥ì¹˜ë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘ì´ì—ìš”..."):
        new_gpt_prompt.append({"role": "user", "content": new_user_prompts[2]})

        gpt_response3 = get_gpt_response("gpt-4o-mini", new_gpt_prompt, stream=False)

        if not gpt_response3 or not gpt_response3.choices or not gpt_response3.choices[0].message.content:
            st.error("âŒ OpenAI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            gpt_response3 = gpt_response3.choices[0].message.content

            try:
                # ğŸ” JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì‘ë‹µ ë‚´ í…ìŠ¤íŠ¸ ì œê±°)
                json_start = gpt_response3.find("{")
                json_end = gpt_response3.rfind("}") + 1
                json_data = gpt_response3[json_start:json_end]

                list_content = json.loads(json_data)

                # ğŸ” 'score' í‚¤ í™•ì¸ í›„ ë³€í™˜
                if "score" not in list_content:
                    st.error("âŒ OpenAI ì‘ë‹µì—ì„œ 'score' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.write("ğŸ” OpenAI ì‘ë‹µ (ë””ë²„ê¹…):", list_content)
                else:
                    df = pd.DataFrame({
                        "r": list_content["score"],
                        "theta": ["ì§ì—…ì í•©ë„", "ë‚œì´ë„", "ì†Œìš”ë¹„ìš©", "ì†Œìš”ê¸°ê°„", "ì˜ˆìƒìˆ˜ì…", "ì—…ë¬´ê°•ë„"]
                    })
                    fig = px.line_polar(df, r="r", theta="theta", line_close=True)
                    fig.update_traces(fill="toself")
                    st.write(fig)
                    st.markdown(list_content["description"])

            except json.JSONDecodeError as e:
                st.error(f"âŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
                st.write("ğŸ” OpenAI ì‘ë‹µ ë‚´ìš©:", gpt_response3)  # ë””ë²„ê¹… ì¶œë ¥


    # ğŸš€ 4ë‹¨ê³„: AIê°€ ê·¸ë¦° ë¯¸ë˜ ëª¨ìŠµ
    if is_answer[3]:
        st.subheader(f"AIê°€ ê·¸ë¦° {name}ë‹˜ì˜ ë¯¸ë˜ ëª¨ìŠµ ğŸ¤–ğŸ”®", divider=True)
        with st.spinner("ë¯¸ë˜ì˜ ë‹¹ì‹ ì„ ê·¸ë¦¬ëŠ” ì¤‘ì´ì—ìš”..."):
            # ì„¸ì…˜ì—ì„œ API í‚¤ ìœ ì§€
            api_key = st.session_state.get("openai_api_key", "")
            if not api_key:
                st.error("ğŸš¨ OpenAI API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

            # OpenAI í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
            client = OpenAI(api_key=api_key)

            # DALL-E ì´ë¯¸ì§€ ìƒì„±
            dalle_response = client.images.generate(
                prompt=f"A portrait of a {job}, an image of a {gender}, cheering and friendly mood, cartoon low poly style.", n=1, size="512x512"
            )
            st.image(dalle_response.data[0].url)

    st.button("ì¹œêµ¬ì—ê²Œ ê³µìœ í•˜ê¸°")