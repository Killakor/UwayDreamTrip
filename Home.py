import streamlit as st
import streamlit.components.v1 as components
import openai
import pandas as pd
import json
import plotly.express as px
from prompts import *

# ğŸ“Œ ë‹µë³€ ì´ˆê¸°í™”
is_answer = [True, True, True, True]

# ğŸ“Œ OpenAI API í‚¤ ë¡œë“œ í•¨ìˆ˜
@st.cache_data
# user í•œê¸€ ì´ìŠˆë¡œ ì¸í•´ ì„ì‹œ ì£¼ì„ ì²˜ë¦¬
# def load_config():
#     """ secrets.tomlì—ì„œ OpenAI API í‚¤ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ """
#     return {"openai_api_key": st.secrets["openai_api_key"]}

# config = load_config()
# openai.api_key = config["openai_api_key"]  # OpenAI API í‚¤ ì„¤ì •

# ğŸ“Œ Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± í•¨ìˆ˜
def mermaid(code):
    """ Mermaid ë‹¤ì´ì–´ê·¸ë¨ì„ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜ """
    components.html(
        f"""
        <pre class="mermaid">
            {code}
        </pre>
        <script type="module">
            import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";
            mermaid.initialize({{ startOnLoad: true, theme: "dark" }});
        </script>
        """,
        height=500,
    )

# ğŸ“Œ OpenAI ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ (GPT)
def get_gpt_response(model, prompt, stream=False):
    """ OpenAI GPT ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ """
    response = openai.ChatCompletion.create(
        model=model,
        messages=prompt,
        stream=stream
    )
    return response


# ğŸ“Œ Streamlit UI ì„¤ì •
st.set_page_config(page_title="Dream Trip - Uway AI ì§„ë¡œ ê²€ì‚¬", layout="wide", page_icon="â­ï¸")

st.header("Dream Trip âœˆï¸âœ¨", divider="rainbow")
st.info("ê¿ˆì„ ìœ„í•œ ë§ì¶¤ ì§„ë¡œ ì—¬í–‰!\n\nì§„ë¡œÂ·ëª©í‘œ ì„¤ì • â†’ ìŠ¤í…ë³„ ê°€ì´ë“œ â†’ ì»¤ë¦¬ì–´ ëª©í‘œ ë‹¬ì„±", icon="âœˆï¸")


# ğŸ“Œ Sidebar (ì‚¬ìš©ì ì…ë ¥)
with st.sidebar:
    st.header("Uway - Dream Trip âœˆï¸", divider="rainbow")

    openai.api_key = st.text_input(label='OpenAI API KEY', placeholder='OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.', value='',type='password')

    if openai.api_key:
        st.session_state["openai_api_key"] = openai.api_key
    st.markdown("---")

    # ì‚¬ìš©ì ì…ë ¥ í¼
    with st.form("parameters-form"):
        st.subheader("ì‚¬ìš©ì ì •ë³´")
        name = st.text_input("ì´ë¦„")
        job = st.text_input("í¬ë§ ì§ì—…")
        age = st.slider("ë‚˜ì´", 10, 20, 17, 1)
        school = st.selectbox("í•™êµ", ["ì¤‘í•™êµ", "ê³ ë“±í•™êµ", "ëŒ€í•™êµ"], index=1)
        mbti = st.selectbox("MBTI", [
            "ISTJ", "ISFJ", "INFJ", "INTJ", "ISTP", "ISFP", "INFP", "INTP",
            "ESTP", "ESFP", "ENFP", "ENTP", "ESTJ", "ESFJ", "ENFJ", "ENTJ"])
        language = st.selectbox("ì–¸ì–´ì„¤ì •", ["ëŒ€í•œë¯¼êµ­", "English", "æ—¥æœ¬", "ä¸­åœ‹"])

        # ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì ìš©
        st.markdown("""
            <style>
                div[data-testid="stForm"] button {
                    width: 100% !important;
                    height: 50px !important;
                    font-size: 16px !important;
                    font-weight: bold !important;
                    background-color: #ff4b4b !important;
                    color: white !important;
                    border-radius: 10px !important;
                    border: none !important;
                }
                div[data-testid="stForm"] button:hover {
                    background-color: #ff7878 !important;
                }
            </style>
        """, unsafe_allow_html=True)

        submit = st.form_submit_button("ì§„ë¡œ ì—¬í–‰ ì‹œì‘í•˜ê¸°")


# ğŸ“Œ OpenAI í”„ë¡¬í”„íŠ¸ ì´ˆê¸° ì„¤ì •
gpt_prompt = [{"role": "system", "content": system_prompt}]


# ğŸ“Œ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if submit and name and job:
    new_gpt_prompt = gpt_prompt.copy()
    new_user_prompts = user_prompts.copy()

    # ğŸš€ 1ë‹¨ê³„: ê¿ˆì˜ ì—¬í–‰ì§€
    if is_answer[0]:
        st.subheader(f"{name}ë‹˜ì˜ ê¿ˆì„ í–¥í•œ ë§ì¶¤ ì—¬í–‰ì§€ ğŸŒˆ", divider=True)
        answer1 = st.empty()

        with st.spinner("ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ì—¬í–‰ì§€ í‹°ì¼“ì„ ë°œí–‰ ì¤‘ì´ì—ìš”..."):
            new_gpt_prompt.append({
                "role": "user",
                "content": new_user_prompts[0] % (name, age, job, school, language, mbti)
            })

            gpt_response1 = get_gpt_response("gpt-4o-mini", new_gpt_prompt, stream=True)

            collected_messages = []
            for chunk in gpt_response1:
                chunk_message = chunk["choices"][0]["delta"]
                if "content" in chunk_message:
                    collected_messages.append(chunk_message["content"])
                    gpt_response1 = "".join(collected_messages)
                    answer1.markdown(f"ğŸ¤– {gpt_response1}")

            new_gpt_prompt.append({"role": "assistant", "content": gpt_response1})


    # ğŸš€ 2ë‹¨ê³„: ê¿ˆìœ¼ë¡œ ê°€ëŠ” ë¡œë“œë§µ
    if is_answer[1]:
        st.subheader(f"{name}ë‹˜ì˜ ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ë¡œë“œë§µ ğŸ—ºï¸ğŸŒŸ", divider=True)
        with st.spinner("ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ë¡œë“œë§µì„ ê·¸ë¦¬ëŠ” ì¤‘ì´ì—ìš”..."):
            new_gpt_prompt.append({
                "role": "user",
                "content": new_user_prompts[1] % (name, age, job, school, language, mbti),
            })

            gpt_response2 = get_gpt_response("gpt-4o-mini", new_gpt_prompt, stream=False)
            gpt_response2 = gpt_response2["choices"][0]["message"]["content"]

            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ íŒŒì‹± ë° ë Œë”ë§
            start_keyword, end_keyword = "```mermaid", "```"
            if start_keyword in gpt_response2 and end_keyword in gpt_response2:
                mermaid_content = gpt_response2.split(start_keyword)[-1].split(end_keyword)[0].strip()
            else:
                mermaid_content = gpt_response2

            mermaid(mermaid_content)


    # ğŸš€ 3ë‹¨ê³„: ì§ì—… ë¶„ì„ ê²°ê³¼
    if is_answer[2]:
        st.subheader(f"AIê°€ ë¶„ì„í•œ {job} ğŸ”ğŸ‘¨â€ğŸ’¼", divider=True)
        with st.spinner("ê¿ˆìœ¼ë¡œ í–¥í•˜ëŠ” ëŠ¥ë ¥ì¹˜ë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘ì´ì—ìš”..."):
            new_gpt_prompt.append({"role": "user", "content": new_user_prompts[2]})

            gpt_response3 = get_gpt_response("gpt-4o-mini", new_gpt_prompt, stream=False)
            gpt_response3 = gpt_response3["choices"][0]["message"]["content"]

            try:
                list_content = json.loads(gpt_response3)
                df = pd.DataFrame({"r": list_content["score"], "theta": ["ì§ì—…ì í•©ë„", "ë‚œì´ë„", "ì†Œìš”ë¹„ìš©", "ì†Œìš”ê¸°ê°„", "ì˜ˆìƒìˆ˜ì…", "ì—…ë¬´ê°•ë„"]})
                fig = px.line_polar(df, r="r", theta="theta", line_close=True)
                fig.update_traces(fill="toself")
                st.write(fig)
                st.markdown(list_content["description"])
            except json.JSONDecodeError:
                st.error("âŒ ì§ì—… ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


    # ğŸš€ 4ë‹¨ê³„: AIê°€ ê·¸ë¦° ë¯¸ë˜ ëª¨ìŠµ
    if is_answer[3]:
        st.subheader(f"AIê°€ ê·¸ë¦° {name}ë‹˜ì˜ ë¯¸ë˜ ëª¨ìŠµ ğŸ¤–ğŸ”®", divider=True)
        with st.spinner("ë¯¸ë˜ì˜ ë‹¹ì‹ ì„ ê·¸ë¦¬ëŠ” ì¤‘ì´ì—ìš”..."):
            dalle_response = openai.Image.create(
                prompt=f"A portrait of a {job}, cheering and friendly mood, cartoon low poly style.",
                n=1, size="512x512"
            )
            st.image(dalle_response['data'][0]['url'])

    st.button("ì¹œêµ¬ì—ê²Œ ê³µìœ í•˜ê¸°")